{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a simple multi-layer perceptron model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Convolutional Neural Network for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\CSCI8363-Fall2017\\keras learning\n"
     ]
    }
   ],
   "source": [
    "# first change the directory\n",
    "import os\n",
    "path = \"D:/CSCI8363-Fall2017/keras learning\"\n",
    "os.chdir(path)\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "X_test_noisy_raw= numpy.loadtxt(open(\"../project idea/noisydata/awgn/test_set.csv\", \"rb\"), delimiter=\",\", skiprows=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 1, 28, 28)\n",
      "(10000, 1, 28, 28)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(repr(X_train.shape)) # considering it is not a RGB image, only one channel of gray images\n",
    "print(repr(X_test.shape))\n",
    "print(repr(X_test_noisy_raw.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "X_test_noisy = X_test_noisy_raw.reshape(X_test_noisy_raw.shape[0], 1, 28, 28).astype('float32')\n",
    "print(repr(X_test_noisy.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n",
      "(10000,)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "y_test_noisy = numpy.loadtxt(open(\"../project idea/noisydata/awgn/test_label.csv\", \"rb\"),\\\n",
    "                             delimiter=\",\", skiprows=0)\n",
    "print (repr(y_test_noisy.shape))\n",
    "print (repr(y_test.shape))\n",
    "y_test_noisy = np_utils.to_categorical(y_test_noisy)\n",
    "print (repr(y_test_noisy.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "X_test_noisy = X_test_noisy/ 255\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Simple_CNN_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (5, 5), input_shape=(1, 28, 28), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 187s - loss: 0.2320 - acc: 0.9342\n",
      "Epoch 2/10\n",
      " - 196s - loss: 0.0736 - acc: 0.9781\n",
      "Epoch 3/10\n",
      " - 194s - loss: 0.0532 - acc: 0.9840\n",
      "Epoch 4/10\n",
      " - 191s - loss: 0.0402 - acc: 0.9880\n",
      "Epoch 5/10\n",
      " - 190s - loss: 0.0335 - acc: 0.9895\n",
      "Epoch 6/10\n",
      " - 193s - loss: 0.0276 - acc: 0.9913\n",
      "Epoch 7/10\n",
      " - 200s - loss: 0.0233 - acc: 0.9927\n",
      "Epoch 8/10\n",
      " - 201s - loss: 0.0205 - acc: 0.9936\n",
      "Epoch 9/10\n",
      " - 203s - loss: 0.0176 - acc: 0.9941\n",
      "Epoch 10/10\n",
      " - 198s - loss: 0.0145 - acc: 0.9957\n",
      "CNN Error: 1.02%\n",
      "CNN Error noisy data: 10.57%\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model = Simple_CNN_model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=200, verbose=2)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))\n",
    "scores1 = model.evaluate(X_test_noisy, y_test_noisy, verbose=0)\n",
    "print(\"CNN Error noisy data: %.2f%%\" % (100-scores1[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
