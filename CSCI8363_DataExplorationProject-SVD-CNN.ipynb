{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the SVD files produced by the preprocessing program to the new directory\n",
    "svd-cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\CSCI8363-Fall2017\\project idea\\svd-cnn\n"
     ]
    }
   ],
   "source": [
    "# first change the directory\n",
    "import os\n",
    "\n",
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' +  directory)\n",
    "\n",
    "\n",
    "path = \"D:\\CSCI8363-Fall2017\\project idea\\svd-cnn\"\n",
    "createFolder(path)\n",
    "os.chdir(path)\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "U0 = np.loadtxt(open(\"SVD_U0.csv\", \"rb\"), delimiter=\",\", skiprows=0)\n",
    "U1 = np.loadtxt(open(\"SVD_U1.csv\", \"rb\"), delimiter=\",\", skiprows=0)\n",
    "U2 = np.loadtxt(open(\"SVD_U2.csv\", \"rb\"), delimiter=\",\", skiprows=0)\n",
    "U3 = np.loadtxt(open(\"SVD_U3.csv\", \"rb\"), delimiter=\",\", skiprows=0)\n",
    "U4 = np.loadtxt(open(\"SVD_U4.csv\", \"rb\"), delimiter=\",\", skiprows=0)\n",
    "U5 = np.loadtxt(open(\"SVD_U5.csv\", \"rb\"), delimiter=\",\", skiprows=0)\n",
    "U6 = np.loadtxt(open(\"SVD_U6.csv\", \"rb\"), delimiter=\",\", skiprows=0)\n",
    "U7 = np.loadtxt(open(\"SVD_U7.csv\", \"rb\"), delimiter=\",\", skiprows=0)\n",
    "U8 = np.loadtxt(open(\"SVD_U8.csv\", \"rb\"), delimiter=\",\", skiprows=0)\n",
    "U9 = np.loadtxt(open(\"SVD_U9.csv\", \"rb\"), delimiter=\",\", skiprows=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784L, 784L)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U9.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduce the dimension of the U matrix and save the only leading 10 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 10\n",
    "U0_reduce = U0[:,0:r]\n",
    "U0_new = np.dot(U0_reduce,np.transpose(U0_reduce))\n",
    "U1_reduce = U1[:,0:r]\n",
    "U1_new = np.dot(U1_reduce,np.transpose(U1_reduce))\n",
    "U2_reduce = U2[:,0:r]\n",
    "U2_new = np.dot(U2_reduce,np.transpose(U2_reduce))\n",
    "U3_reduce = U3[:,0:r]\n",
    "U3_new = np.dot(U3_reduce,np.transpose(U3_reduce))\n",
    "U4_reduce = U4[:,0:r]\n",
    "U4_new = np.dot(U4_reduce,np.transpose(U4_reduce))\n",
    "U5_reduce = U5[:,0:r]\n",
    "U5_new = np.dot(U5_reduce,np.transpose(U5_reduce))\n",
    "U6_reduce = U6[:,0:r]\n",
    "U6_new = np.dot(U6_reduce,np.transpose(U6_reduce))\n",
    "U7_reduce = U7[:,0:r]\n",
    "U7_new = np.dot(U7_reduce,np.transpose(U7_reduce))\n",
    "U8_reduce = U8[:,0:r]\n",
    "U8_new = np.dot(U8_reduce,np.transpose(U8_reduce))\n",
    "U9_reduce = U9[:,0:r]\n",
    "U9_new = np.dot(U9_reduce,np.transpose(U9_reduce))\n",
    "U_assembly = np.zeros((784,784,10)) # Make a 10 by 20 by 30 array\n",
    "U_assembly[:,:,0] = U0_new\n",
    "U_assembly[:,:,1] = U1_new\n",
    "U_assembly[:,:,2] = U2_new\n",
    "U_assembly[:,:,3] = U3_new\n",
    "U_assembly[:,:,4] = U4_new\n",
    "U_assembly[:,:,5] = U5_new\n",
    "U_assembly[:,:,6] = U6_new\n",
    "U_assembly[:,:,7] = U7_new\n",
    "U_assembly[:,:,8] = U8_new\n",
    "U_assembly[:,:,9] = U9_new\n",
    "\n",
    "U_reduce_assembly = np.zeros((784,10,10)) # Make a 10 by 20 by 30 array\n",
    "U_reduce_assembly[:,:,0] = U0_reduce\n",
    "U_reduce_assembly[:,:,1] = U1_reduce\n",
    "U_reduce_assembly[:,:,2] = U2_reduce\n",
    "U_reduce_assembly[:,:,3] = U3_reduce\n",
    "U_reduce_assembly[:,:,4] = U4_reduce\n",
    "U_reduce_assembly[:,:,5] = U5_reduce\n",
    "U_reduce_assembly[:,:,6] = U6_reduce\n",
    "U_reduce_assembly[:,:,7] = U7_reduce\n",
    "U_reduce_assembly[:,:,8] = U8_reduce\n",
    "U_reduce_assembly[:,:,9] = U9_reduce\n",
    "U_reduce_assembly_total = np.zeros((784,100)) # Make a 10 by 20 by 30 array\n",
    "U_reduce_assembly_total = np.concatenate((U0_reduce, U1_reduce, U2_reduce, U3_reduce, U4_reduce,\\\n",
    "                           U5_reduce, U6_reduce, U7_reduce, U8_reduce, U9_reduce), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(784, 10, 10)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train.shape\n",
    "print(y_train.shape)\n",
    "U_reduce_assembly= np.asarray(U_reduce_assembly)\n",
    "U_reduce_assembly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_coefficient = np.zeros((X_train.shape[0],10))\n",
    "for i in range(X_train.shape[0]):\n",
    "    a = U_reduce_assembly[:,:,y_train[i]]\n",
    "    b = np.linalg.lstsq(a, X_train[i,:,:].reshape(784))\n",
    "    X_train_coefficient[i,:]= b[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_coefficient = np.zeros((X_test.shape[0],10))\n",
    "for i in range(X_test.shape[0]):\n",
    "    atest= U_reduce_assembly[:,:,y_test[i]]\n",
    "    btest = np.linalg.lstsq(atest, X_test[i,:,:].reshape(784))\n",
    "    X_test_coefficient[i,:] = b[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train_new = X_train_coefficient.reshape(X_train_coefficient.shape[0], 1, 1 , 10).astype('float32')\n",
    "X_test_new = X_test_coefficient.reshape(X_test_coefficient.shape[0], 1, 1, 10).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one hot encode outputs, change to binary matrix\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Simple_CNN_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (1, 1), input_shape=(1, 1, 10), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(1, 1)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(20, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 5s - loss: 13.9850 - acc: 0.1215\n",
      "Epoch 2/10\n",
      " - 5s - loss: 13.6380 - acc: 0.1436\n",
      "Epoch 3/10\n",
      " - 5s - loss: 13.4353 - acc: 0.1546\n",
      "Epoch 4/10\n",
      " - 5s - loss: 13.2755 - acc: 0.1638\n",
      "Epoch 5/10\n",
      " - 5s - loss: 11.8427 - acc: 0.1598\n",
      "Epoch 6/10\n",
      " - 5s - loss: 2.3676 - acc: 0.1124\n",
      "Epoch 7/10\n",
      " - 5s - loss: 2.3126 - acc: 0.1124\n",
      "Epoch 8/10\n",
      " - 5s - loss: 2.3063 - acc: 0.1124\n",
      "Epoch 9/10\n",
      " - 5s - loss: 2.3039 - acc: 0.1124\n",
      "Epoch 10/10\n",
      " - 5s - loss: 2.3025 - acc: 0.1125\n",
      "CNN Error: 88.65%\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model = Simple_CNN_model()\n",
    "# Fit the model\n",
    "model.fit(X_train_new, y_train, epochs=10, batch_size=200, verbose=2)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test_new, y_test, verbose=0)\n",
    "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))\n",
    "#scores1 = model.evaluate(X_test_noisy, y_test_noisy, verbose=0)\n",
    "#print(\"CNN Error noisy data: %.2f%%\" % (100-scores1[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
